---
year: 1994
date: 1994-01-01
authors:
  - "Plate, T."
  - "Hinton, Geoffrey E."
generated: true
key: FISSVQXQ
version: 2548
itemType: conferencePaper
paperTitle: Distributed representations and nested compositional structure
url: "https://www.semanticscholar.org/paper/Distributed-representations-and-nested-structure-Plate-Hinton/aad5b4340e4b3b23ad8d292bf9ed8e7f60c53159"
accessDate: "2025-04-22T09:09:19Z"
libraryCatalog: Semantic Scholar
dateAdded: "2025-04-22T09:09:19Z"
dateModified: "2025-04-22T09:09:19Z"
filename: Plate and Hinton 1994 - Distributed representations and nested compositional structure.pdf
marker: "[ðŸ‡¿](zotero://select/library/items/FISSVQXQ)"
publish: true
type: reference
---
# Distributed representations and nested compositional structure

[PDF file](/Papers/PDFs/Plate%20and%20Hinton%201994%20-%20Distributed%20representations%20and%20nested%20compositional%20structure.pdf)

> [!abstract] Abstract
> Distributed representations are attractive for a number of reasons. They offer the possibility of representing concepts in a continuous space, they degrade gracefully with noise, and they can be processed in a parallel network of simple processing elements. However, the problem of representing nested structure in distributed representations has been for some time a prominent concern of both proponents and critics of connectionism (Fodor and Pylyshyn 1988; Smolensky 1990; Hinton 1990). The lack of connectionist representations for complex structure has held back progress in tackling higher-level cognitive tasks such as language understanding and reasoning. 
> In this thesis I review connectionist representations and propose a method for the distributed representation of nested structure, which I call "Holographic Reduced Representations" (HRRs). HRRs provide an implementation of Hinton's (1990) "reduced descriptions". HRRs use circular convolution to associate atomic items, which are represented by vectors. Arbitrary variable bindings, short sequences of various lengths, and predicates can be represented in a fixed-width vector. These representations are items in their own right, and can be used in constructing compositional structures. The noisy reconstructions extracted from convolution memories can be cleaned up by using a separate associative memory that has good reconstructive properties. 
> Circular convolution, which is the basic associative operator for HRRs, can be built into a recurrent neural network. The network can store and produce sequences. I show that neural network learning techniques can be used with circular convolution in order to learn representations for items and sequences. 
> One of the attractions of connectionist representations of compositional structures is the possibility of computing without decomposing structures. I show that it is possible to use dot-product comparisons of HRRs for nested structures to estimate the analogical similarity of the structures. This demonstrates how the surface form of connectionist representations can reflect underlying structural similarity and alignment.

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it.

