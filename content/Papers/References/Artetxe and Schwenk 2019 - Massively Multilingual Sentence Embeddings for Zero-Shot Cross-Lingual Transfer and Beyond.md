---
year: 2019
month: 11
date: 11/2019
authors:
  - "Artetxe, Mikel"
  - "Schwenk, Holger"
generated: true
key: G9NLPVGU
version: 2236
itemType: journalArticle
title: Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond
publicationTitle: Transactions of the Association for Computational Linguistics
volume: 7
pages: 597-610
journalAbbreviation: Transactions of the Association for Computational Linguistics
language: en
DOI: 10.1162/tacl_a_00288
ISSN: 2307-387X
url: "https://direct.mit.edu/tacl/article/43523"
accessDate: "2024-05-14T09:10:32Z"
libraryCatalog: Semantic Scholar
collections:
  - ERQKEKFA
dateAdded: "2024-05-14T09:10:32Z"
dateModified: "2024-05-14T09:10:37Z"
super_collections:
  - ERQKEKFA
filename: Artetxe and Schwenk 2019 - Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond
marker: "[ðŸ‡¿](zotero://select/library/items/G9NLPVGU)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond

> [!example] File
> [Artetxe and Schwenk 2019 - Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond](Artetxe%20and%20Schwenk%202019%20-%20Massively%20Multilingual%20Sentence%20Embeddings%20for%20Zero-Shot%20Cross-Lingual%20Transfer%20and%20Beyond.pdf)

> [!abstract] Abstract
> We introduce an architecture to learn joint multilingual sentence representations for 93 languages, belonging to more than 30 different families and written in 28 different scripts. Our system uses a single BiLSTM encoder with a shared byte-pair encoding vocabulary for all languages, which is coupled with an auxiliary decoder and trained on publicly available parallel corpora. This enables us to learn a classifier on top of the resulting embeddings using English annotated data only, and transfer it to any of the 93 languages without any modification. Our experiments in cross-lingual natural language inference (XNLI data set), cross-lingual document classification (MLDoc data set), and parallel corpus mining (BUCC data set) show the effectiveness of our approach. We also introduce a new test set of aligned sentences in 112 languages, and show that our sentence embeddings obtain strong results in multilingual similarity search even for low- resource languages. Our implementation, the pre-trained encoder, and the multilingual test set are available at https://github.com/facebookresearch/LASER .

