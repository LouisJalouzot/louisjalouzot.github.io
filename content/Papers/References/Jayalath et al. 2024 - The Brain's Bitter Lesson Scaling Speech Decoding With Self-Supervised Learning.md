---
zoteroTags:
  - "FOS: Computer and information sciences"
  - Machine Learning (cs.LG)
year: 2024
date: 2024
authors:
  - "Jayalath, Dulhan"
  - "Landau, Gilad"
  - "Shillingford, Brendan"
  - "Woolrich, Mark"
  - "Jones, Oiwi Parker"
generated: true
key: 368ZRVIE
version: 2259
itemType: journalArticle
title: "The Brain's Bitter Lesson: Scaling Speech Decoding With Self-Supervised Learning"
DOI: 10.48550/ARXIV.2406.04328
shortTitle: The Brain's Bitter Lesson
url: "https://arxiv.org/abs/2406.04328"
accessDate: "2024-11-25T09:13:32Z"
libraryCatalog: Semantic Scholar
rights: Creative Commons Attribution 4.0 International
extra: "Publisher: arXiv Version Number: 3"
collections:
  - ERQKEKFA
dateAdded: "2024-11-25T09:13:32Z"
dateModified: "2024-11-25T09:20:04Z"
super_collections:
  - ERQKEKFA
filename: Jayalath et al. 2024 - The Brain's Bitter Lesson Scaling Speech Decoding With Self-Supervised Learning
marker: "[ðŸ‡¿](zotero://select/library/items/368ZRVIE)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] The Brain's Bitter Lesson: Scaling Speech Decoding With Self-Supervised Learning

> [!example] File
> [Jayalath et al. 2024 - The Brain's Bitter Lesson Scaling Speech Decoding With Self-Supervised Learning](Jayalath%20et%20al.%202024%20-%20The%20Brain's%20Bitter%20Lesson%20Scaling%20Speech%20Decoding%20With%20Self-Supervised%20Learning.pdf)

> [!abstract] Abstract
> The past few years have produced a series of spectacular advances in the decoding of speech from brain activity. The engine of these advances has been the acquisition of labelled data, with increasingly large datasets acquired from single subjects. However, participants exhibit individual differences, such as anatomy, and datasets use varied scanners and task designs. As a result, prior work has struggled to leverage data from multiple subjects, multiple datasets, multiple tasks, and unlabelled datasets. In turn, the field has not benefited from the rapidly growing number of open neural data repositories to exploit large-scale data and deep learning. This gap exists for all neural data, but especially for magnetoencephalography (MEG), where the scale of individual datasets has not yet caught up with other modalities. To address this, we develop a set of neuroscience-inspired self-supervised objectives, together with a neural architecture, for representation learning from heterogeneous and unlabelled neural recordings. Experimental results with MEG show that representations learned with these objectives scale with data, generalise across subjects, datasets, and tasks, outperform using the raw input representation, and even surpass comparable self-supervised approaches. In addition, we set new benchmarks for two foundational speech decoding tasks. Collectively, these methods now unlock the potential for training speech decoding models with orders of magnitude more existing data.

