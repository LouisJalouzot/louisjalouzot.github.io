---
zoteroTags:
  - Computer Science - Artificial Intelligence
  - Computer Science - Machine Learning
  - Statistics - Machine Learning
year: 2023
month: 10
day: 25
date: 2023-10-25
authors:
  - "Chamma, Ahmad"
  - "Engemann, Denis A."
  - "Thirion, Bertrand"
generated: true
key: 3CU4FTKC
version: 2239
itemType: preprint
title: Statistically Valid Variable Importance Assessment through Conditional Permutations
repository: arXiv
archiveID: "arXiv:2309.07593"
DOI: 10.48550/arXiv.2309.07593
url: "http://arxiv.org/abs/2309.07593"
accessDate: "2024-04-03T16:12:30Z"
libraryCatalog: arXiv.org
extra: "arXiv:2309.07593 [cs, stat]"
collections:
  - ERQKEKFA
dateAdded: "2024-04-03T16:12:30Z"
dateModified: "2024-04-03T16:12:35Z"
super_collections:
  - ERQKEKFA
filename: Chamma et al. 2023 - Statistically Valid Variable Importance Assessment through Conditional Permutations
marker: "[ðŸ‡¿](zotero://select/library/items/3CU4FTKC)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Statistically Valid Variable Importance Assessment through Conditional Permutations

> [!example] File
> [Chamma et al. 2023 - Statistically Valid Variable Importance Assessment through Conditional Permutations](Chamma%20et%20al.%202023%20-%20Statistically%20Valid%20Variable%20Importance%20Assessment%20through%20Conditional%20Permutations.pdf)

> [!abstract] Abstract
> Variable importance assessment has become a crucial step in machine-learning applications when using complex learners, such as deep neural networks, on large-scale data. Removal-based importance assessment is currently the reference approach, particularly when statistical guarantees are sought to justify variable inclusion. It is often implemented with variable permutation schemes. On the flip side, these approaches risk misidentifying unimportant variables as important in the presence of correlations among covariates. Here we develop a systematic approach for studying Conditional Permutation Importance (CPI) that is model agnostic and computationally lean, as well as reusable benchmarks of state-of-the-art variable importance estimators. We show theoretically and empirically that $\textit{CPI}$ overcomes the limitations of standard permutation importance by providing accurate type-I error control. When used with a deep neural network, $\textit{CPI}$ consistently showed top accuracy across benchmarks. An experiment on real-world data analysis in a large-scale medical dataset showed that $\textit{CPI}$ provides a more parsimonious selection of statistically significant variables. Our results suggest that $\textit{CPI}$ can be readily used as drop-in replacement for permutation-based methods.

