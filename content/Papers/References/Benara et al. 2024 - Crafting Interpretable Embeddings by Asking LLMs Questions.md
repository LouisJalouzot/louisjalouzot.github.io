---
zoteroTags:
  - Artificial Intelligence (cs.AI)
  - Computation and Language (cs.CL)
  - "FOS: Biological sciences"
  - "FOS: Computer and information sciences"
  - Machine Learning (cs.LG)
  - Neurons and Cognition (q-bio.NC)
year: 2024
date: 2024
authors:
  - "Benara, Vinamra"
  - "Singh, Chandan"
  - "Morris, John X."
  - "Antonello, Richard"
  - "Stoica, Ion"
  - "Huth, Alexander G."
  - "Gao, Jianfeng"
generated: true
key: SSFFYXET
version: 2257
itemType: journalArticle
title: Crafting Interpretable Embeddings by Asking LLMs Questions
DOI: 10.48550/ARXIV.2405.16714
url: "https://arxiv.org/abs/2405.16714"
accessDate: "2024-11-12T20:33:26Z"
libraryCatalog: Semantic Scholar
rights: Creative Commons Attribution 4.0 International
extra: "Publisher: arXiv Version Number: 1"
collections:
  - ERQKEKFA
dateAdded: "2024-11-12T20:33:26Z"
dateModified: "2024-11-12T20:33:37Z"
super_collections:
  - ERQKEKFA
filename: Benara et al. 2024 - Crafting Interpretable Embeddings by Asking LLMs Questions
marker: "[ðŸ‡¿](zotero://select/library/items/SSFFYXET)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Crafting Interpretable Embeddings by Asking LLMs Questions

> [!example] File
> [Benara et al. 2024 - Crafting Interpretable Embeddings by Asking LLMs Questions](Benara%20et%20al.%202024%20-%20Crafting%20Interpretable%20Embeddings%20by%20Asking%20LLMs%20Questions.pdf)

> [!abstract] Abstract
> Large language models (LLMs) have rapidly improved text embeddings for a growing array of natural-language processing tasks. However, their opaqueness and proliferation into scientific domains such as neuroscience have created a growing need for interpretability. Here, we ask whether we can obtain interpretable embeddings through LLM prompting. We introduce question-answering embeddings (QA-Emb), embeddings where each feature represents an answer to a yes/no question asked to an LLM. Training QA-Emb reduces to selecting a set of underlying questions rather than learning model weights.
>  We use QA-Emb to flexibly generate interpretable models for predicting fMRI voxel responses to language stimuli. QA-Emb significantly outperforms an established interpretable baseline, and does so while requiring very few questions. This paves the way towards building flexible feature spaces that can concretize and evaluate our understanding of semantic brain representations. We additionally find that QA-Emb can be effectively approximated with an efficient model, and we explore broader applications in simple NLP tasks.

