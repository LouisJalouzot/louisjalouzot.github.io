---
year: 2025
month: 3
day: 17
date: 2025-04-16
authors:
  - "Mueller, Aaron"
  - "Geiger, Atticus"
  - "Wiegreffe, Sarah"
  - "Arad, Dana"
  - "Arcuschin, Iv'an"
  - "Belfki, Adam"
  - "Chan, Yik Siu"
  - "Fiotto-Kaufman, Jaden"
  - "Haklay, Tal"
  - "Hanna, Michael"
  - "Huang, Jing"
  - "Gupta, Rohan"
  - "Nikankin, Yaniv"
  - "Orgad, Hadas"
  - "Prakash, Nikhil"
  - "Reusch, Anja"
  - "Sankaranarayanan, Aruna"
  - "Shao, Shun"
  - "Stolfo, Alessandro"
  - "Tutek, Martin"
  - "Zur, Amir"
  - "Bau, David"
  - "Belinkov, Yonatan"
generated: true
key: CJU4TP4H
version: 2552
itemType: conferencePaper
paperTitle: "MIB: A Mechanistic Interpretability Benchmark"
shortTitle: MIB
url: "https://www.semanticscholar.org/paper/MIB%3A-A-Mechanistic-Interpretability-Benchmark-Mueller-Geiger/66583ad76bc1ce493ed3b530b9a56f87a7e684ca"
accessDate: "2025-04-23T14:03:25Z"
libraryCatalog: Semantic Scholar
dateAdded: "2025-04-23T14:03:25Z"
dateModified: "2025-04-23T14:03:25Z"
filename: Mueller et al. 2025 - MIB A Mechanistic Interpretability Benchmark.pdf
marker: "[ðŸ‡¿](zotero://select/library/items/CJU4TP4H)"
publish: true
type: reference
---
# MIB: A Mechanistic Interpretability Benchmark

[PDF file](/Papers/PDFs/Mueller%20et%20al.%202025%20-%20MIB%20A%20Mechanistic%20Interpretability%20Benchmark.pdf)

> [!abstract] Abstract
> How can we know whether new mechanistic interpretability methods achieve real improvements? In pursuit of meaningful and lasting evaluation standards, we propose MIB, a benchmark with two tracks spanning four tasks and five models. MIB favors methods that precisely and concisely recover relevant causal pathways or specific causal variables in neural language models. The circuit localization track compares methods that locate the model components - and connections between them - most important for performing a task (e.g., attribution patching or information flow routes). The causal variable localization track compares methods that featurize a hidden vector, e.g., sparse autoencoders (SAEs) or distributed alignment search (DAS), and locate model features for a causal variable relevant to the task. Using MIB, we find that attribution and mask optimization methods perform best on circuit localization. For causal variable localization, we find that the supervised DAS method performs best, while SAE features are not better than neurons, i.e., standard dimensions of hidden vectors. These findings illustrate that MIB enables meaningful comparisons of methods, and increases our confidence that there has been real progress in the field.

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it.

