---
year: 2024
month: 11
day: 12
date: 2024-11-12
authors:
  - "Luettgau, Lennart"
  - "Erdmann, Tore"
  - "Veselic, Sebastijan"
  - "Stachenfeld, Kimberly L."
  - "Kurth-Nelson, Zeb"
  - "Moran, Rani"
  - "Dolan, Raymond J."
generated: true
key: IDF8BQSF
version: 2266
itemType: journalArticle
title: Decomposing dynamical subprocesses for compositional generalization
publicationTitle: Proceedings of the National Academy of Sciences
volume: 121
issue: 46
pages: e2408134121
journalAbbreviation: Proc. Natl. Acad. Sci. U.S.A.
language: en
DOI: 10.1073/pnas.2408134121
ISSN: "0027-8424, 1091-6490"
url: "https://pnas.org/doi/10.1073/pnas.2408134121"
accessDate: "2025-01-18T11:24:38Z"
libraryCatalog: Semantic Scholar
collections:
  - ERQKEKFA
dateAdded: "2025-01-18T11:24:38Z"
dateModified: "2025-01-18T11:27:34Z"
super_collections:
  - ERQKEKFA
filename: Luettgau et al. 2024 - Decomposing dynamical subprocesses for compositional generalization
marker: "[ðŸ‡¿](zotero://select/library/items/IDF8BQSF)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Decomposing dynamical subprocesses for compositional generalization

> [!example] File
> [Luettgau et al. 2024 - Decomposing dynamical subprocesses for compositional generalization](Luettgau%20et%20al.%202024%20-%20Decomposing%20dynamical%20subprocesses%20for%20compositional%20generalization.pdf)

> [!abstract] Abstract
> A striking feature of human cognition is an exceptional ability to rapidly adapt to novel situations. It is proposed this relies on abstracting and generalizing past experiences. While previous research has explored how humans detect and generalize single sequential processes, we have a limited understanding of how humans adapt to more naturalistic scenarios, for example, complex, multisubprocess environments. Here, we propose a candidate computational mechanism that posits compositional generalization of knowledge about subprocess dynamics. In two samples (
>               N
>               = 238 and
>               N
>               = 137), we combined a novel sequence learning task and computational modeling to ask whether humans extract and generalize subprocesses compositionally to solve new problems. In prior learning, participants experienced sequences of compound images formed from two graphsâ€™ product spaces (group 1: G1 and G2, group 2: G3 and G4). In transfer learning, both groups encountered compound images from the product of G1 and G3, composed entirely of new images. We show that subprocess knowledge transferred between task phases, such that in a new task environment each group had enhanced accuracy in predicting subprocess dynamics they had experienced during prior learning. Computational models utilizing predictive representations, based solely on the temporal contiguity of experienced task states, without an ability to transfer knowledge, failed to explain these data. Instead, behavior was consistent with a predictive representation model that maps task states between prior and transfer learning. These results help advance a mechanistic understanding of how humans discover and abstract subprocesses composing their experiences and compositionally reuse prior knowledge as a scaffolding for new experiences.

