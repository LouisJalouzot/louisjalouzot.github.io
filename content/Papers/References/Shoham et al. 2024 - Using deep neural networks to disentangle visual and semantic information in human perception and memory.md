---
zoteroTags:
  - Human behaviour
year: 2024
month: 2
day: 8
date: 2024-02-08
authors:
  - "Shoham, Adva"
  - "Grosbard, Idan Daniel"
  - "Patashnik, Or"
  - "Cohen-Or, Daniel"
  - "Yovel, Galit"
generated: true
key: AWDBPSS4
version: 2243
itemType: journalArticle
title: Using deep neural networks to disentangle visual and semantic information in human perception and memory
publicationTitle: Nature Human Behaviour
pages: 1-16
journalAbbreviation: Nat Hum Behav
language: en
DOI: 10.1038/s41562-024-01816-9
ISSN: 2397-3374
url: "https://www.nature.com/articles/s41562-024-01816-9"
accessDate: "2024-03-09T04:10:08Z"
libraryCatalog: www.nature.com
rights: "2024 The Author(s), under exclusive licence to Springer Nature Limited"
extra: "Publisher: Nature Publishing Group"
collections:
  - ERQKEKFA
dateAdded: "2024-03-09T04:10:08Z"
dateModified: "2024-03-09T04:10:12Z"
super_collections:
  - ERQKEKFA
filename: Shoham et al. 2024 - Using deep neural networks to disentangle visual and semantic information in human perception and memory
marker: "[ðŸ‡¿](zotero://select/library/items/AWDBPSS4)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Using deep neural networks to disentangle visual and semantic information in human perception and memory

> [!example] File
> [Shoham et al. 2024 - Using deep neural networks to disentangle visual and semantic information in human perception and memory](Shoham%20et%20al.%202024%20-%20Using%20deep%20neural%20networks%20to%20disentangle%20visual%20and%20semantic%20information%20in%20human%20perception%20and%20memory.pdf)

> [!abstract] Abstract
> Mental representations of familiar categories are composed of visual and semantic information. Disentangling the contributions of visual and semantic information in humans is challenging because they are intermixed in mental representations. Deep neural networks that are trained either on images or on text or by pairing images and text enable us now to disentangle human mental representations into their visual, visualâ€“semantic and semantic components. Here we used these deep neural networks to uncover the content of human mental representations of familiar faces and objects when they are viewed or recalled from memory. The results show a larger visual than semantic contribution when images are viewed and a reversed pattern when they are recalled. We further reveal a previously unknown unique contribution of an integrated visualâ€“semantic representation in both perception and memory. We propose a new framework in which visual and semantic information contribute independently and interactively to mental representations in perception and memory.

