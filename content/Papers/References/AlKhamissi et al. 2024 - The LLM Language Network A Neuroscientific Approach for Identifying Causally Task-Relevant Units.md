---
zoteroTags:
  - Computation and Language (cs.CL)
  - "FOS: Computer and information sciences"
  - Machine Learning (cs.LG)
year: 2024
date: 2024
authors:
  - "AlKhamissi, Badr"
  - "Tuckute, Greta"
  - "Bosselut, Antoine"
  - "Schrimpf, Martin"
generated: true
key: FECSHITT
version: 2265
itemType: journalArticle
title: "The LLM Language Network: A Neuroscientific Approach for Identifying Causally Task-Relevant Units"
DOI: 10.48550/ARXIV.2411.02280
shortTitle: The LLM Language Network
url: "https://arxiv.org/abs/2411.02280"
accessDate: "2025-01-18T11:22:58Z"
libraryCatalog: Semantic Scholar
rights: Creative Commons Attribution Non Commercial Share Alike 4.0 International
extra: "Publisher: arXiv Version Number: 1"
collections:
  - ERQKEKFA
dateAdded: "2025-01-18T11:22:58Z"
dateModified: "2025-01-18T11:27:38Z"
super_collections:
  - ERQKEKFA
filename: AlKhamissi et al. 2024 - The LLM Language Network A Neuroscientific Approach for Identifying Causally Task-Relevant Units
marker: "[ðŸ‡¿](zotero://select/library/items/FECSHITT)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] The LLM Language Network: A Neuroscientific Approach for Identifying Causally Task-Relevant Units

> [!example] File
> [AlKhamissi et al. 2024 - The LLM Language Network A Neuroscientific Approach for Identifying Causally Task-Relevant Units](AlKhamissi%20et%20al.%202024%20-%20The%20LLM%20Language%20Network%20A%20Neuroscientific%20Approach%20for%20Identifying%20Causally%20Task-Relevant%20Units.pdf)

> [!abstract] Abstract
> Large language models (LLMs) exhibit remarkable capabilities on not just language tasks, but also various tasks that are not linguistic in nature, such as logical reasoning and social inference. In the human brain, neuroscience has identified a core language system that selectively and causally supports language processing. We here ask whether similar specialization for language emerges in LLMs. We identify language-selective units within 18 popular LLMs, using the same localization approach that is used in neuroscience. We then establish the causal role of these units by demonstrating that ablating LLM language-selective units -- but not random units -- leads to drastic deficits in language tasks. Correspondingly, language-selective LLM units are more aligned to brain recordings from the human language system than random units. Finally, we investigate whether our localization method extends to other cognitive domains: while we find specialized networks in some LLMs for reasoning and social capabilities, there are substantial differences among models. These findings provide functional and causal evidence for specialization in large language models, and highlight parallels with the functional organization in the brain.

