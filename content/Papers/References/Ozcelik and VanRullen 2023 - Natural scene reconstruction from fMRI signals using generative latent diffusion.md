---
year: 2023
month: 9
day: 20
date: 2023-09-20
authors:
  - "Ozcelik, Furkan"
  - "VanRullen, Rufin"
generated: true
key: FI8EIY7J
version: 2238
itemType: journalArticle
title: Natural scene reconstruction from fMRI signals using generative latent diffusion
publicationTitle: Scientific Reports
volume: 13
issue: 1
pages: 15666
journalAbbreviation: Sci Rep
language: en
DOI: 10.1038/s41598-023-42891-8
ISSN: 2045-2322
url: "https://www.nature.com/articles/s41598-023-42891-8"
accessDate: "2024-04-23T10:12:57Z"
libraryCatalog: Semantic Scholar
collections:
  - ERQKEKFA
dateAdded: "2024-04-23T10:12:57Z"
dateModified: "2024-04-23T10:13:03Z"
super_collections:
  - ERQKEKFA
filename: Ozcelik and VanRullen 2023 - Natural scene reconstruction from fMRI signals using generative latent diffusion
marker: "[üáø](zotero://select/library/items/FI8EIY7J)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Natural scene reconstruction from fMRI signals using generative latent diffusion

> [!example] File
> [Ozcelik and VanRullen 2023 - Natural scene reconstruction from fMRI signals using generative latent diffusion](Ozcelik%20and%20VanRullen%202023%20-%20Natural%20scene%20reconstruction%20from%20fMRI%20signals%20using%20generative%20latent%20diffusion.pdf)

> [!abstract] Abstract
> Abstract
>             In neural decoding research, one of the most intriguing topics is the reconstruction of perceived natural images based on fMRI signals. Previous studies have succeeded in re-creating different aspects of the visuals, such as low-level properties (shape, texture, layout) or high-level features (category of objects, descriptive semantics of scenes) but have typically failed to reconstruct these properties together for complex scene images. Generative AI has recently made a leap forward with latent diffusion models capable of generating high-complexity images. Here, we investigate how to take advantage of this innovative technology for brain decoding. We present a two-stage scene reconstruction framework called ‚ÄúBrain-Diffuser‚Äù. In the first stage, starting from fMRI signals, we reconstruct images that capture low-level properties and overall layout using a VDVAE (Very Deep Variational Autoencoder) model. In the second stage, we use the image-to-image framework of a latent diffusion model (Versatile Diffusion) conditioned on predicted multimodal (text and visual) features, to generate final reconstructed images. On the publicly available Natural Scenes Dataset benchmark, our method outperforms previous models both qualitatively and quantitatively. When applied to synthetic fMRI patterns generated from individual ROI (region-of-interest) masks, our trained model creates compelling ‚ÄúROI-optimal‚Äù scenes consistent with neuroscientific knowledge. Thus, the proposed methodology can have an impact on both applied (e.g. brain‚Äìcomputer interface) and fundamental neuroscience.

