---
year: 2017
month: 4
date: 5/2017
authors:
  - "Biesmans, Wouter"
  - "Das, Neetha"
  - "Francart, Tom"
  - "Bertrand, Alexander"
generated: true
key: NTK83EKL
version: 2283
itemType: journalArticle
paperTitle: Auditory-Inspired Speech Envelope Extraction Methods for Improved EEG-Based Auditory Attention Detection in a Cocktail Party Scenario
publicationTitle: IEEE Transactions on Neural Systems and Rehabilitation Engineering
volume: 25
issue: 5
pages: 402-412
journalAbbreviation: IEEE Trans. Neural Syst. Rehabil. Eng.
DOI: 10.1109/TNSRE.2016.2571900
ISSN: "1534-4320, 1558-0210"
url: "https://ieeexplore.ieee.org/document/7478117/"
accessDate: "2025-03-03T20:37:25Z"
libraryCatalog: Semantic Scholar
rights: "https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html"
dateAdded: "2025-03-03T20:37:25Z"
dateModified: "2025-03-03T20:37:25Z"
filename: Biesmans et al. 2017 - Auditory-Inspired Speech Envelope Extraction Methods for Improved EEG-Based Auditory Attention Detection in a Cocktail Party Scenario.pdf
marker: "[ðŸ‡¿](zotero://select/library/items/NTK83EKL)"
publish: true
---
# Auditory-Inspired Speech Envelope Extraction Methods for Improved EEG-Based Auditory Attention Detection in a Cocktail Party Scenario

[PDF file](/Papers/PDFs/Biesmans%20et%20al.%202017%20-%20Auditory-Inspired%20Speech%20Envelope%20Extraction%20Methods%20for%20Improved%20EEG-Based%20Auditory%20Attention%20Detection%20in%20a%20Cocktail%20Party%20Scenario.pdf)

> [!abstract] Abstract
> This paper considers the auditory attention detection (AAD) paradigm, where the goal is to determine which of two simultaneous speakers a person is attending to. The paradigm relies on recordings of the listenerâ€™s brain activity, e.g., from electroencephalography (EEG). To perform AAD, decoded EEG signals are typically correlated with the temporal envelopes of the speech signals of the separate speakers. In this paper, we study how the inclusion of various degrees of auditory modelling in this speech envelope extraction process affects the AAD performance, where the best performance is found for an auditory-inspired linear filter bank followed by power law compression. These two modelling stages are computationally cheap, which is important for implementation in wearable devices, such as future neuro-steered auditory prostheses. We also introduce a more natural way to combine recordings (over trials and subjects) to train the decoder, which reduces the dependence of the algorithm on regularization parameters. Finally, we investigate the simultaneous design of the EEG decoder and the audio subband envelope recombination weights vector using either a norm-constrained least squares or a canonical correlation analysis, but conclude that this increases computational complexity without improving AAD performance.

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it.

