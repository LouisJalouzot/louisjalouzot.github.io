---
zoteroTags:
  - Computation and Language (cs.CL)
  - "FOS: Computer and information sciences"
  - Human-Computer Interaction (cs.HC)
year: 2024
date: 2024
authors:
  - "Chen, Xiaoyu"
  - "Du, Changde"
  - "Liu, Che"
  - "Wang, Yizhe"
  - "He, Huiguang"
generated: true
key: SY7VBR2P
version: 2258
itemType: journalArticle
title: Open-vocabulary Auditory Neural Decoding Using fMRI-prompted LLM
DOI: 10.48550/ARXIV.2405.07840
url: "https://arxiv.org/abs/2405.07840"
accessDate: "2024-11-25T09:12:25Z"
libraryCatalog: Semantic Scholar
rights: Creative Commons Attribution 4.0 International
extra: "Publisher: arXiv Version Number: 1"
collections:
  - ERQKEKFA
dateAdded: "2024-11-25T09:12:25Z"
dateModified: "2024-11-25T09:13:47Z"
super_collections:
  - ERQKEKFA
filename: Chen et al. 2024 - Open-vocabulary Auditory Neural Decoding Using fMRI-prompted LLM
marker: "[ðŸ‡¿](zotero://select/library/items/SY7VBR2P)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Open-vocabulary Auditory Neural Decoding Using fMRI-prompted LLM

> [!example] File
> [Chen et al. 2024 - Open-vocabulary Auditory Neural Decoding Using fMRI-prompted LLM](Chen%20et%20al.%202024%20-%20Open-vocabulary%20Auditory%20Neural%20Decoding%20Using%20fMRI-prompted%20LLM.pdf)

> [!abstract] Abstract
> Decoding language information from brain signals represents a vital research area within brain-computer interfaces, particularly in the context of deciphering the semantic information from the fMRI signal. However, many existing efforts concentrate on decoding small vocabulary sets, leaving space for the exploration of open vocabulary continuous text decoding. In this paper, we introduce a novel method, the \textbf{Brain Prompt GPT (BP-GPT)}. By using the brain representation that is extracted from the fMRI as a prompt, our method can utilize GPT-2 to decode fMRI signals into stimulus text. Further, we introduce a text-to-text baseline and align the fMRI prompt to the text prompt. By introducing the text-to-text baseline, our BP-GPT can extract a more robust brain prompt and promote the decoding of pre-trained LLM. We evaluate our BP-GPT on the open-source auditory semantic decoding dataset and achieve a significant improvement up to $4.61\%$ on METEOR and $2.43\%$ on BERTScore across all the subjects compared to the state-of-the-art method. The experimental results demonstrate that using brain representation as a prompt to further drive LLM for auditory neural decoding is feasible and effective.

