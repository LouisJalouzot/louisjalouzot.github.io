---
year: 2017
month: 10
day: 25
date: 25 October 2017
authors:
  - "Zhang, Hongyi"
  - "CissÃ©, Moustapha"
  - "Dauphin, Yann"
  - "Lopez-Paz, David"
generated: true
key: GESXSKWB
version: 2233
itemType: journalArticle
title: "mixup: Beyond Empirical Risk Minimization"
publicationTitle: ArXiv
shortTitle: mixup
url: "https://www.semanticscholar.org/paper/mixup%3A-Beyond-Empirical-Risk-Minimization-Zhang-Ciss%C3%A9/4feef0fd284feb1233399b400eb897f59ec92755"
accessDate: "2024-06-02T08:46:38Z"
libraryCatalog: Semantic Scholar
collections:
  - ERQKEKFA
dateAdded: "2024-06-02T08:46:38Z"
dateModified: "2024-06-02T08:46:48Z"
super_collections:
  - ERQKEKFA
filename: Zhang et al. 2017 - mixup Beyond Empirical Risk Minimization
marker: "[ðŸ‡¿](zotero://select/library/items/GESXSKWB)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] mixup: Beyond Empirical Risk Minimization

> [!example] File
> [Zhang et al. 2017 - mixup Beyond Empirical Risk Minimization](Zhang%20et%20al.%202017%20-%20mixup%20Beyond%20Empirical%20Risk%20Minimization.pdf)

> [!abstract] Abstract
> Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also find that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks.

