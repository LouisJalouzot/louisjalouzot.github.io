---
zoteroTags:
  - "FOS: Computer and information sciences"
  - Machine Learning (cs.LG)
year: 2022
date: 2022
authors:
  - "Elhage, Nelson"
  - "Hume, Tristan"
  - "Olsson, Catherine"
  - "Schiefer, Nicholas"
  - "Henighan, Tom"
  - "Kravec, Shauna"
  - "Hatfield-Dodds, Zac"
  - "Lasenby, Robert"
  - "Drain, Dawn"
  - "Chen, Carol"
  - "Grosse, Roger"
  - "McCandlish, Sam"
  - "Kaplan, Jared"
  - "Amodei, Dario"
  - "Wattenberg, Martin"
  - "Olah, Christopher"
generated: true
key: 2RBXG8SM
version: 2261
itemType: journalArticle
title: Toy Models of Superposition
DOI: 10.48550/ARXIV.2209.10652
url: "https://arxiv.org/abs/2209.10652"
accessDate: "2024-12-05T14:53:15Z"
libraryCatalog: Semantic Scholar
rights: "arXiv.org perpetual, non-exclusive license"
extra: "Publisher: arXiv Version Number: 1"
deleted: 1
collections:
  - ERQKEKFA
dateAdded: "2024-12-05T14:53:15Z"
dateModified: "2024-12-05T14:53:21Z"
super_collections:
  - ERQKEKFA
filename: Elhage et al. 2022 - Toy Models of Superposition
marker: "[ðŸ‡¿](zotero://select/library/items/2RBXG8SM)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Toy Models of Superposition

> [!example] File
> [Elhage et al. 2022 - Toy Models of Superposition](Elhage%20et%20al.%202022%20-%20Toy%20Models%20of%20Superposition.pdf)

> [!abstract] Abstract
> Neural networks often pack many unrelated concepts into a single neuron - a puzzling phenomenon known as 'polysemanticity' which makes interpretability much more challenging. This paper provides a toy model where polysemanticity can be fully understood, arising as a result of models storing additional sparse features in "superposition." We demonstrate the existence of a phase change, a surprising connection to the geometry of uniform polytopes, and evidence of a link to adversarial examples. We also discuss potential implications for mechanistic interpretability.

