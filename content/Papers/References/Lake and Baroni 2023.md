---
year: 2023
month: 10
day: 2
date: 2023-11-02
authors:
  - "Lake, Brenden M."
  - "Baroni, Marco"
generated: true
key: SQU4ZALA
version: 2302
itemType: journalArticle
paperTitle: Human-like systematic generalization through a meta-learning neural network
publicationTitle: Nature
volume: 623
issue: 7985
pages: 115-121
journalAbbreviation: Nature
language: en
DOI: 10.1038/s41586-023-06668-3
ISSN: "0028-0836, 1476-4687"
url: "https://www.nature.com/articles/s41586-023-06668-3"
accessDate: "2025-03-05T10:12:22Z"
libraryCatalog: Semantic Scholar
dateAdded: "2025-03-05T10:12:22Z"
dateModified: "2025-03-05T10:12:22Z"
filename: Lake and Baroni 2023 - Human-like systematic generalization through a meta-learning neural network.pdf
marker: "[ðŸ‡¿](zotero://select/library/items/SQU4ZALA)"
---
# Human-like systematic generalization through a meta-learning neural network

[PDF file](/Papers/PDFs/Lake%20and%20Baroni%202023%20-%20Human-like%20systematic%20generalization%20through%20a%20meta-learning%20neural%20network.pdf)

> [!abstract] Abstract
> Abstract
>             
>               The power of human language and thought arises from systematic compositionalityâ€”the algebraic ability to understand and produce novel combinations from known components. Fodor and Pylyshyn
>               1
>               famously argued that artificial neural networks lack this capacity and are therefore not viable models of the mind. Neural networks have advanced considerably in the years since, yet the systematicity challenge persists. Here we successfully address Fodor and Pylyshynâ€™s challenge by providing evidence that neural networks can achieve human-like systematicity when optimized for their compositional skills. To do so, we introduce the meta-learning for compositionality (MLC) approach for guiding training through a dynamic stream of compositional tasks. To compare humans and machines, we conducted human behavioural experiments using anÂ instruction learning paradigm. After considering seven different models, we found that, in contrast to perfectly systematic but rigid probabilistic symbolic models, and perfectly flexible but unsystematic neural networks, only MLC achieves both the systematicity and flexibility needed for human-like generalization. MLC also advances the compositional skills of machine learning systems in several systematic generalization benchmarks. Our results show how a standard neural network architecture, optimized for its compositional skills, can mimic human systematic generalization in a head-to-head comparison.

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it.

