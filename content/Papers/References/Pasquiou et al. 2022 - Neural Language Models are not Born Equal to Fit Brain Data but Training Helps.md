---
zoteroTags:
  - Computer Science - Artificial Intelligence
  - Computer Science - Computation and Language
year: 2022
month: 7
day: 7
date: 2022-07-07
authors:
  - "Pasquiou, Alexandre"
  - "Lakretz, Yair"
  - "Hale, John"
  - "Thirion, Bertrand"
  - "Pallier, Christophe"
generated: true
key: 5AXQYJCS
version: 2241
itemType: preprint
title: "Neural Language Models are not Born Equal to Fit Brain Data, but Training Helps"
repository: arXiv
archiveID: "arXiv:2207.03380"
DOI: 10.48550/arXiv.2207.03380
url: "http://arxiv.org/abs/2207.03380"
accessDate: "2024-03-12T14:21:21Z"
libraryCatalog: arXiv.org
extra: "arXiv:2207.03380 [cs]"
collections:
  - ERQKEKFA
dateAdded: "2024-03-12T14:21:21Z"
dateModified: "2024-03-12T14:21:24Z"
super_collections:
  - ERQKEKFA
filename: Pasquiou et al. 2022 - Neural Language Models are not Born Equal to Fit Brain Data but Training Helps
marker: "[ðŸ‡¿](zotero://select/library/items/5AXQYJCS)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Neural Language Models are not Born Equal to Fit Brain Data, but Training Helps

> [!example] File
> [Pasquiou et al. 2022 - Neural Language Models are not Born Equal to Fit Brain Data but Training Helps](Pasquiou%20et%20al.%202022%20-%20Neural%20Language%20Models%20are%20not%20Born%20Equal%20to%20Fit%20Brain%20Data%20but%20Training%20Helps.pdf)

> [!abstract] Abstract
> Neural Language Models (NLMs) have made tremendous advances during the last years, achieving impressive performance on various linguistic tasks. Capitalizing on this, studies in neuroscience have started to use NLMs to study neural activity in the human brain during language processing. However, many questions remain unanswered regarding which factors determine the ability of a neural language model to capture brain activity (aka its 'brain score'). Here, we make first steps in this direction and examine the impact of test loss, training corpus and model architecture (comparing GloVe, LSTM, GPT-2 and BERT), on the prediction of functional Magnetic Resonance Imaging timecourses of participants listening to an audiobook. We find that (1) untrained versions of each model already explain significant amount of signal in the brain by capturing similarity in brain responses across identical words, with the untrained LSTM outperforming the transformerbased models, being less impacted by the effect of context; (2) that training NLP models improves brain scores in the same brain regions irrespective of the model's architecture; (3) that Perplexity (test loss) is not a good predictor of brain score; (4) that training data have a strong influence on the outcome and, notably, that off-the-shelf models may lack statistical power to detect brain activations. Overall, we outline the impact of modeltraining choices, and suggest good practices for future studies aiming at explaining the human language system using neural language models.

