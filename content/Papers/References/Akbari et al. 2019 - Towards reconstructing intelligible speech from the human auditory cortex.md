---
year: 2019
month: 1
day: 29
date: 2019-01-29
authors:
  - "Akbari, Hassan"
  - "Khalighinejad, Bahar"
  - "Herrero, Jose L."
  - "Mehta, Ashesh D."
  - "Mesgarani, Nima"
generated: true
key: 9AP8YKZM
version: 2235
itemType: journalArticle
title: Towards reconstructing intelligible speech from the human auditory cortex
publicationTitle: Scientific Reports
volume: 9
issue: 1
pages: 874
journalAbbreviation: Sci Rep
language: en
DOI: 10.1038/s41598-018-37359-z
ISSN: 2045-2322
url: "https://www.nature.com/articles/s41598-018-37359-z"
accessDate: "2024-05-31T11:05:11Z"
libraryCatalog: Semantic Scholar
collections:
  - ERQKEKFA
dateAdded: "2024-05-31T11:05:11Z"
dateModified: "2024-05-31T11:05:22Z"
super_collections:
  - ERQKEKFA
filename: Akbari et al. 2019 - Towards reconstructing intelligible speech from the human auditory cortex
marker: "[ðŸ‡¿](zotero://select/library/items/9AP8YKZM)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Towards reconstructing intelligible speech from the human auditory cortex

> [!example] File
> [Akbari et al. 2019 - Towards reconstructing intelligible speech from the human auditory cortex](Akbari%20et%20al.%202019%20-%20Towards%20reconstructing%20intelligible%20speech%20from%20the%20human%20auditory%20cortex.pdf)

> [!abstract] Abstract
> Abstract
>             Auditory stimulus reconstruction is a technique that finds the best approximation of the acoustic stimulus from the population of evoked neural activity. Reconstructing speech from the human auditory cortex creates the possibility of a speech neuroprosthetic to establish a direct communication with the brain and has been shown to be possible in both overt and covert conditions. However, the low quality of the reconstructed speech has severely limited the utility of this method for brain-computer interface (BCI) applications. To advance the state-of-the-art in speech neuroprosthesis, we combined the recent advances in deep learning with the latest innovations in speech synthesis technologies to reconstruct closed-set intelligible speech from the human auditory cortex. We investigated the dependence of reconstruction accuracy on linear and nonlinear (deep neural network) regression methods and the acoustic representation that is used as the target of reconstruction, including auditory spectrogram and speech synthesis parameters. In addition, we compared the reconstruction accuracy from low and high neural frequency ranges. Our results show that a deep neural network model that directly estimates the parameters of a speech synthesizer from all neural frequencies achieves the highest subjective and objective scores on a digit recognition task, improving the intelligibility by 65% over the baseline method which used linear regression to reconstruct the auditory spectrogram. These results demonstrate the efficacy of deep learning and speech synthesis algorithms for designing the next generation of speech BCI systems, which not only can restore communications for paralyzed patients but also have the potential to transform human-computer interaction technologies.

