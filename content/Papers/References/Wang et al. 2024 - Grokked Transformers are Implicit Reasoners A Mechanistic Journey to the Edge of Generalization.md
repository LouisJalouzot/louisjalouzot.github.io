---
year: 2024
month: 5
day: 23
date: 23 May 2024
authors:
  - "Wang, Boshi"
  - "Yue, Xiang"
  - "Su, Yu"
  - "Sun, Huan"
generated: true
key: 9CXMWGAL
version: 2234
itemType: conferencePaper
title: "Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization"
shortTitle: Grokked Transformers are Implicit Reasoners
url: "https://www.semanticscholar.org/paper/Grokked-Transformers-are-Implicit-Reasoners%3A-A-to-Wang-Yue/5b1120f547d3969afc49b4a094e874d568e53aca"
accessDate: "2024-05-31T20:32:32Z"
libraryCatalog: Semantic Scholar
collections:
  - ERQKEKFA
dateAdded: "2024-05-31T20:32:32Z"
dateModified: "2024-05-31T20:32:43Z"
super_collections:
  - ERQKEKFA
filename: Wang et al. 2024 - Grokked Transformers are Implicit Reasoners A Mechanistic Journey to the Edge of Generalization
marker: "[ðŸ‡¿](zotero://select/library/items/9CXMWGAL)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization

> [!example] File
> [Wang et al. 2024 - Grokked Transformers are Implicit Reasoners A Mechanistic Journey to the Edge of Generalization](Wang%20et%20al.%202024%20-%20Grokked%20Transformers%20are%20Implicit%20Reasoners%20A%20Mechanistic%20Journey%20to%20the%20Edge%20of%20Generalization.pdf)

> [!abstract] Abstract
> We study whether transformers can learn to implicitly reason over parametric knowledge, a skill that even the most capable language models struggle with. Focusing on two representative reasoning types, composition and comparison, we consistently find that transformers can learn implicit reasoning, but only through grokking, i.e., extended training far beyond overfitting. The levels of generalization also vary across reasoning types: when faced with out-of-distribution examples, transformers fail to systematically generalize for composition but succeed for comparison. We delve into the model's internals throughout training, conducting analytical experiments that reveal: 1) the mechanism behind grokking, such as the formation of the generalizing circuit and its relation to the relative efficiency of generalizing and memorizing circuits, and 2) the connection between systematicity and the configuration of the generalizing circuit. Our findings guide data and training setup to better induce implicit reasoning and suggest potential improvements to the transformer architecture, such as encouraging cross-layer knowledge sharing. Furthermore, we demonstrate that for a challenging reasoning task with a large search space, GPT-4-Turbo and Gemini-1.5-Pro based on non-parametric memory fail badly regardless of prompting styles or retrieval augmentation, while a fully grokked transformer can achieve near-perfect accuracy, showcasing the power of parametric memory for complex reasoning.

