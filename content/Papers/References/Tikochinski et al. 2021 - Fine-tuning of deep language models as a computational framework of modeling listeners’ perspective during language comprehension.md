---
year: 2021
month: 11
day: 23
date: 2021-11-23
authors:
  - "Tikochinski, Refael"
  - "Goldstein, Ariel"
  - "Yeshurun, Yaara"
  - "Hasson, Uri"
  - "Reichart, Roi"
generated: true
key: 5Q748PNC
version: 2237
itemType: journalArticle
title: Fine-tuning of deep language models as a computational framework of modeling listenersâ€™ perspective during language comprehension
language: en
DOI: 10.1101/2021.11.22.469596
url: "http://biorxiv.org/lookup/doi/10.1101/2021.11.22.469596"
accessDate: "2024-05-07T23:15:49Z"
libraryCatalog: Neuroscience
collections:
  - ERQKEKFA
dateAdded: "2024-05-07T23:15:49Z"
dateModified: "2024-05-07T23:15:55Z"
super_collections:
  - ERQKEKFA
filename: Tikochinski et al. 2021 - Fine-tuning of deep language models as a computational framework of modeling listenersâ€™ perspective during language comprehension
marker: "[ðŸ‡¿](zotero://select/library/items/5Q748PNC)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Fine-tuning of deep language models as a computational framework of modeling listenersâ€™ perspective during language comprehension

> [!example] File
> [Tikochinski et al. 2021 - Fine-tuning of deep language models as a computational framework of modeling listenersâ€™ perspective during language comprehension](Tikochinski%20et%20al.%202021%20-%20Fine-tuning%20of%20deep%20language%20models%20as%20a%20computational%20framework%20of%20modeling%20listenersâ€™%20perspective%20during%20language%20comprehension.pdf)

> [!abstract] Abstract
> Abstract
>           Computational Deep Language Models (DLMs) have been shown to be effective in predicting neural responses during natural language processing. This study introduces a novel computational framework, based on the concept of fine-tuning (Hinton, 2007), for modeling differences in interpretation of narratives based on the listenersâ€™ perspective (i.e. their prior knowledge, thoughts, and beliefs). We draw on an fMRI experiment conducted by Yeshurun et al. (2017), in which two groups of listeners were listening to the same narrative but with two different perspectives (cheating versus paranoia). We collected a dedicated dataset of ~3000 stories, and used it to create two modified (fine-tuned) versions of a pre-trained DLM, each representing the perspective of a different group of listeners. Information extracted from each of the two fine-tuned models was better fitted with neural responses of the corresponding group of listeners. Furthermore, we show that the degree of difference between the listenersâ€™ interpretation of the story - as measured both neurally and behaviorally - can be approximated using the distances between the representations of the story extracted from these two fine-tuned models. These models-brain associations were expressed in many language-related brain areas, as well as in several higher-order areas related to the default-mode and the mentalizing networks, therefore implying that computational fine-tuning reliably captures relevant aspects of human language comprehension across different levels of cognitive processing.

