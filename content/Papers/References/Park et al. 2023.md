---
zoteroTags:
  - Artificial Intelligence (cs.AI)
  - Computation and Language (cs.CL)
  - "FOS: Computer and information sciences"
  - Machine Learning (cs.LG)
  - Machine Learning (stat.ML)
year: 2023
date: 2023
authors:
  - "Park, Kiho"
  - "Choe, Yo Joong"
  - "Veitch, Victor"
generated: true
key: MDG3HBCR
version: 2322
itemType: journalArticle
paperTitle: The Linear Representation Hypothesis and the Geometry of Large Language Models
DOI: 10.48550/ARXIV.2311.03658
url: "https://arxiv.org/abs/2311.03658"
accessDate: "2025-03-07T17:35:02Z"
libraryCatalog: Semantic Scholar
rights: Creative Commons Attribution Non Commercial Share Alike 4.0 International
extra: "Publisher: arXiv Version Number: 2"
dateAdded: "2025-03-07T17:35:02Z"
dateModified: "2025-03-07T17:35:02Z"
filename: Park et al. 2023 - The Linear Representation Hypothesis and the Geometry of Large Language Models.pdf
marker: "[ðŸ‡¿](zotero://select/library/items/MDG3HBCR)"
publish: true
---
# The Linear Representation Hypothesis and the Geometry of Large Language Models

[PDF file](/Papers/PDFs/Park%20et%20al.%202023%20-%20The%20Linear%20Representation%20Hypothesis%20and%20the%20Geometry%20of%20Large%20Language%20Models.pdf)

> [!abstract] Abstract
> Informally, the 'linear representation hypothesis' is the idea that high-level concepts are represented linearly as directions in some representation space. In this paper, we address two closely related questions: What does "linear representation" actually mean? And, how do we make sense of geometric notions (e.g., cosine similarity or projection) in the representation space? To answer these, we use the language of counterfactuals to give two formalizations of "linear representation", one in the output (word) representation space, and one in the input (sentence) space. We then prove these connect to linear probing and model steering, respectively. To make sense of geometric notions, we use the formalization to identify a particular (non-Euclidean) inner product that respects language structure in a sense we make precise. Using this causal inner product, we show how to unify all notions of linear representation. In particular, this allows the construction of probes and steering vectors using counterfactual pairs. Experiments with LLaMA-2 demonstrate the existence of linear representations of concepts, the connection to interpretation and control, and the fundamental role of the choice of inner product.

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it.

