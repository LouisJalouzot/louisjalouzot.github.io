---
year: 2020
month: 7
date: 7/2020
authors:
  - "Clark, Peter"
  - "Tafjord, Oyvind"
  - "Richardson, Kyle"
generated: true
key: M6KA2FGG
version: 2257
itemType: conferencePaper
title: Transformers as Soft Reasoners over Language
proceedingsTitle: Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence
conferenceName: "Twenty-Ninth International Joint Conference on Artificial Intelligence and Seventeenth Pacific Rim International Conference on Artificial Intelligence {IJCAI-PRICAI-20}"
place: "Yokohama, Japan"
publisher: International Joint Conferences on Artificial Intelligence Organization
pages: 3882-3890
language: en
DOI: 10.24963/ijcai.2020/537
ISBN: 978-0-9992411-6-5
url: "https://www.ijcai.org/proceedings/2020/537"
accessDate: "2024-11-13T15:01:18Z"
libraryCatalog: Semantic Scholar
collections:
  - ERQKEKFA
dateAdded: "2024-11-13T15:01:18Z"
dateModified: "2024-11-13T15:01:31Z"
super_collections:
  - ERQKEKFA
filename: Clark et al. 2020 - Transformers as Soft Reasoners over Language
marker: "[ðŸ‡¿](zotero://select/library/items/M6KA2FGG)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Transformers as Soft Reasoners over Language

> [!example] File
> [Clark et al. 2020 - Transformers as Soft Reasoners over Language](Clark%20et%20al.%202020%20-%20Transformers%20as%20Soft%20Reasoners%20over%20Language.pdf)

> [!abstract] Abstract
> Beginning with McCarthy's Advice Taker (1959), AI has pursued the goal of providing a system with explicit, general knowledge and having the system reason over that knowledge. However, expressing the knowledge in a formal (logical or probabilistic) representation has been a major obstacle to this research. This paper investigates a modern approach to this problem where the facts and rules are provided as natural language sentences, thus bypassing a formal representation. We train transformers to reason (or emulate reasoning) over these sentences using synthetically generated data. Our models, that we call RuleTakers, provide the first empirical demonstration that this kind of soft reasoning over language is learnable, can achieve high (99%) accuracy, and generalizes to test data requiring substantially deeper chaining than seen during training (95%+ scores). We also demonstrate that the models transfer well to two hand-authored rulebases, and to rulebases paraphrased into more natural language. These findings are significant as it suggests a new role for transformers, namely as limited "soft theorem provers" operating over explicit theories in language. This in turn suggests new possibilities for explainability, correctability, and counterfactual reasoning in question-answering.

