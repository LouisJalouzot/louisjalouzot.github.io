---
zoteroTags:
  - Artificial Intelligence (cs.AI)
  - "FOS: Computer and information sciences"
year: 2022
date: 2022
authors:
  - "Qiao, Ximing"
  - "Li, Hai"
generated: true
key: 7LDNVBTY
version: 2270
itemType: journalArticle
title: "Learning and Compositionality: a Unification Attempt via Connectionist Probabilistic Programming"
DOI: 10.48550/ARXIV.2208.12789
shortTitle: Learning and Compositionality
url: "https://arxiv.org/abs/2208.12789"
accessDate: "2025-02-11T02:24:29Z"
libraryCatalog: Semantic Scholar
rights: Creative Commons Attribution 4.0 International
extra: "Publisher: arXiv Version Number: 1"
collections:
  - ERQKEKFA
dateAdded: "2025-02-11T02:24:29Z"
dateModified: "2025-02-11T03:53:27Z"
super_collections:
  - ERQKEKFA
filename: Qiao and Li 2022 - Learning and Compositionality a Unification Attempt via Connectionist Probabilistic Programming
marker: "[ðŸ‡¿](zotero://select/library/items/7LDNVBTY)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Learning and Compositionality: a Unification Attempt via Connectionist Probabilistic Programming

> [!example] File
> [Qiao and Li 2022 - Learning and Compositionality a Unification Attempt via Connectionist Probabilistic Programming](Qiao%20and%20Li%202022%20-%20Learning%20and%20Compositionality%20a%20Unification%20Attempt%20via%20Connectionist%20Probabilistic%20Programming.pdf)

> [!abstract] Abstract
> We consider learning and compositionality as the key mechanisms towards simulating human-like intelligence. While each mechanism is successfully achieved by neural networks and symbolic AIs, respectively, it is the combination of the two mechanisms that makes human-like intelligence possible. Despite the numerous attempts on building hybrid neuralsymbolic systems, we argue that our true goal should be unifying learning and compositionality, the core mechanisms, instead of neural and symbolic methods, the surface approaches to achieve them. In this work, we review and analyze the strengths and weaknesses of neural and symbolic methods by separating their forms and meanings (structures and semantics), and propose Connectionist Probabilistic Program (CPPs), a framework that connects connectionist structures (for learning) and probabilistic program semantics (for compositionality). Under the framework, we design a CPP extension for small scale sequence modeling and provide a learning algorithm based on Bayesian inference. Although challenges exist in learning complex patterns without supervision, our early results demonstrate CPP's successful extraction of concepts and relations from raw sequential data, an initial step towards compositional learning.

