---
zoteroTags:
  - Computer Science - Computation and Language
year: 2025
month: 2
day: 3
date: 2025-03-03
authors:
  - "AlKhamissi, Badr"
  - "Tuckute, Greta"
  - "Tang, Yingtian"
  - "Binhuraib, Taha"
  - "Bosselut, Antoine"
  - "Schrimpf, Martin"
generated: true
key: FAJYFHCT
version: 2342
itemType: preprint
paperTitle: "From Language to Cognition: How LLMs Outgrow the Human Language Network"
repository: arXiv
archiveID: "arXiv:2503.01830"
DOI: 10.48550/arXiv.2503.01830
url: "http://arxiv.org/abs/2503.01830"
accessDate: "2025-03-12T15:28:57Z"
shortTitle: From Language to Cognition
libraryCatalog: arXiv.org
extra: "arXiv:2503.01830 [cs]"
dateAdded: "2025-03-12T15:28:57Z"
dateModified: "2025-03-12T15:28:57Z"
filename: AlKhamissi et al. 2025 - From Language to Cognition How LLMs Outgrow the Human Language Network.pdf
marker: "[ðŸ‡¿](zotero://select/library/items/FAJYFHCT)"
publish: true
type: reference
---
# From Language to Cognition: How LLMs Outgrow the Human Language Network

[PDF file](/Papers/PDFs/AlKhamissi%20et%20al.%202025%20-%20From%20Language%20to%20Cognition%20How%20LLMs%20Outgrow%20the%20Human%20Language%20Network.pdf)

> [!abstract] Abstract
> Large language models (LLMs) exhibit remarkable similarity to neural activity in the human language network. However, the key properties of language shaping brain-like representations, and their evolution during training as a function of different tasks remain unclear. We here benchmark 34 training checkpoints spanning 300B tokens across 8 different model sizes to analyze how brain alignment relates to linguistic competence. Specifically, we find that brain alignment tracks the development of formal linguistic competence -- i.e., knowledge of linguistic rules -- more closely than functional linguistic competence. While functional competence, which involves world knowledge and reasoning, continues to develop throughout training, its relationship with brain alignment is weaker, suggesting that the human language network primarily encodes formal linguistic structure rather than broader cognitive functions. We further show that model size is not a reliable predictor of brain alignment when controlling for feature size and find that the correlation between next-word prediction, behavioral alignment and brain alignment fades once models surpass human language proficiency. Finally, using the largest set of rigorous neural language benchmarks to date, we show that language brain alignment benchmarks remain unsaturated, highlighting opportunities for improving future models. Taken together, our findings suggest that the human language network is best modeled by formal, rather than functional, aspects of language.

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it.

