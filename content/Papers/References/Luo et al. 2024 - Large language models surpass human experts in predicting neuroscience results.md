---
zoteroTags:
  - Computer Science - Artificial Intelligence
  - Quantitative Biology - Neurons and Cognition
year: 2024
month: 3
day: 4
date: 2024-03-04
authors:
  - "Luo, Xiaoliang"
  - "Rechardt, Akilles"
  - "Sun, Guangzhi"
  - "Nejad, Kevin K."
  - "YÃ¡Ã±ez, Felipe"
  - "Yilmaz, Bati"
  - "Lee, Kangjoo"
  - "Cohen, Alexandra O."
  - "Borghesani, Valentina"
  - "Pashkov, Anton"
  - "Marinazzo, Daniele"
  - "Nicholas, Jonathan"
  - "Salatiello, Alessandro"
  - "Sucholutsky, Ilia"
  - "Minervini, Pasquale"
  - "Razavi, Sepehr"
  - "Rocca, Roberta"
  - "Yusifov, Elkhan"
  - "Okalova, Tereza"
  - "Gu, Nianlong"
  - "Ferianc, Martin"
  - "Khona, Mikail"
  - "Patil, Kaustubh R."
  - "Lee, Pui-Shee"
  - "Mata, Rui"
  - "Myers, Nicholas E."
  - "Bizley, Jennifer K."
  - "Musslick, Sebastian"
  - "Bilgin, Isil Poyraz"
  - "Niso, Guiomar"
  - "Ales, Justin M."
  - "Gaebler, Michael"
  - "Murty, N. Apurva Ratan"
  - "Hall, Chloe M."
  - "Dafflon, Jessica"
  - "Bao, Sherry Dongqi"
  - "Love, Bradley C."
generated: true
key: IKKP95E9
version: 2243
itemType: preprint
title: Large language models surpass human experts in predicting neuroscience results
repository: arXiv
archiveID: "arXiv:2403.03230"
url: "http://arxiv.org/abs/2403.03230"
accessDate: "2024-03-09T04:15:59Z"
libraryCatalog: arXiv.org
extra: "arXiv:2403.03230 [cs, q-bio]"
collections:
  - ERQKEKFA
dateAdded: "2024-03-09T04:15:59Z"
dateModified: "2024-03-09T04:16:15Z"
super_collections:
  - ERQKEKFA
filename: Luo et al. 2024 - Large language models surpass human experts in predicting neuroscience results
marker: "[ðŸ‡¿](zotero://select/library/items/IKKP95E9)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Large language models surpass human experts in predicting neuroscience results

> [!example] File
> [Luo et al. 2024 - Large language models surpass human experts in predicting neuroscience results](Luo%20et%20al.%202024%20-%20Large%20language%20models%20surpass%20human%20experts%20in%20predicting%20neuroscience%20results.pdf)

> [!abstract] Abstract
> Scientific discoveries often hinge on synthesizing decades of research, a task that potentially outstrips human information processing capacities. Large language models (LLMs) offer a solution. LLMs trained on the vast scientific literature could potentially integrate noisy yet interrelated findings to forecast novel results better than human experts. To evaluate this possibility, we created BrainBench, a forward-looking benchmark for predicting neuroscience results. We find that LLMs surpass experts in predicting experimental outcomes. BrainGPT, an LLM we tuned on the neuroscience literature, performed better yet. Like human experts, when LLMs were confident in their predictions, they were more likely to be correct, which presages a future where humans and LLMs team together to make discoveries. Our approach is not neuroscience-specific and is transferable to other knowledge-intensive endeavors.

