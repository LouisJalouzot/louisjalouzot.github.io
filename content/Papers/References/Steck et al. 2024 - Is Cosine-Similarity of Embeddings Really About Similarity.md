---
zoteroTags:
  - Computer Science - Information Retrieval
  - Computer Science - Machine Learning
year: 2024
month: 3
day: 8
date: 2024-03-08
authors:
  - "Steck, Harald"
  - "Ekanadham, Chaitanya"
  - "Kallus, Nathan"
generated: true
key: QRVNHW59
version: 2241
itemType: preprint
title: "Is Cosine-Similarity of Embeddings Really About Similarity?"
DOI: 10.1145/3589335.3651526
url: "http://arxiv.org/abs/2403.05440"
accessDate: "2024-03-11T16:12:36Z"
libraryCatalog: arXiv.org
extra: "arXiv:2403.05440 [cs]"
collections:
  - ERQKEKFA
dateAdded: "2024-03-11T16:12:36Z"
dateModified: "2024-03-11T16:12:47Z"
super_collections:
  - ERQKEKFA
filename: Steck et al. 2024 - Is Cosine-Similarity of Embeddings Really About Similarity
marker: "[ðŸ‡¿](zotero://select/library/items/QRVNHW59)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] Is Cosine-Similarity of Embeddings Really About Similarity?

> [!example] File
> [Steck et al. 2024 - Is Cosine-Similarity of Embeddings Really About Similarity](Steck%20et%20al.%202024%20-%20Is%20Cosine-Similarity%20of%20Embeddings%20Really%20About%20Similarity.pdf)

> [!abstract] Abstract
> Cosine-similarity is the cosine of the angle between two vectors, or equivalently the dot product between their normalizations. A popular application is to quantify semantic similarity between high-dimensional objects by applying cosine-similarity to a learned low-dimensional feature embedding. This can work better but sometimes also worse than the unnormalized dot-product between embedded vectors in practice. To gain insight into this empirical observation, we study embeddings derived from regularized linear models, where closed-form solutions facilitate analytical insights. We derive analytically how cosine-similarity can yield arbitrary and therefore meaningless `similarities.' For some linear models the similarities are not even unique, while for others they are implicitly controlled by the regularization. We discuss implications beyond linear models: a combination of different regularizations are employed when learning deep models; these have implicit and unintended effects when taking cosine-similarities of the resulting embeddings, rendering results opaque and possibly arbitrary. Based on these insights, we caution against blindly using cosine-similarity and outline alternatives.

