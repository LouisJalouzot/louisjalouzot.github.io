---
year: 2008
month: 11
day: 7
date: 2008-11-07
authors:
  - "Formisano, Elia"
  - "De Martino, Federico"
  - "Bonte, Milene"
  - "Goebel, Rainer"
generated: true
key: P9XJJGR2
version: 2047
itemType: journalArticle
title: "\"Who\" Is Saying \"What\"? Brain-Based Decoding of Human Voice and Speech"
publicationTitle: Science
volume: 322
issue: 5903
pages: 970-973
journalAbbreviation: Science
language: en
DOI: 10.1126/science.1164318
ISSN: "0036-8075, 1095-9203"
shortTitle: "\"Who\" Is Saying \"What\"?"
url: "https://www.science.org/doi/10.1126/science.1164318"
accessDate: "2025-02-21T10:25:10Z"
libraryCatalog: Semantic Scholar
collections:
  - ERQKEKFA
dateAdded: "2025-02-21T10:25:10Z"
dateModified: "2025-02-21T10:25:10Z"
super_collections:
  - ERQKEKFA
filename: Formisano et al. 2008 - Who Is Saying What Brain-Based Decoding of Human Voice and Speech
marker: "[üáø](zotero://select/library/items/P9XJJGR2)"
---

>[!warning] Warning
> This note should not be modified as it can be overwritten by the plugin which generated it

> [!title] "Who" Is Saying "What"? Brain-Based Decoding of Human Voice and Speech

> [!example] File
> [Formisano et al. 2008 - Who Is Saying What Brain-Based Decoding of Human Voice and Speech](Formisano%20et%20al.%202008%20-%20Who%20Is%20Saying%20What%20Brain-Based%20Decoding%20of%20Human%20Voice%20and%20Speech.pdf)

> [!abstract] Abstract
> Can we decipher speech content (‚Äúwhat‚Äù is being said) and speaker identity (‚Äúwho‚Äù is saying it) from observations of brain activity of a listener? Here, we combine functional magnetic resonance imaging with a data-mining algorithm and retrieve what and whom a person is listening to from the neural fingerprints that speech and voice signals elicit in the listener's auditory cortex. These cortical fingerprints are spatially distributed and insensitive to acoustic variations of the input so as to permit the brain-based recognition of learned speech from unknown speakers and of learned voices from previously unheard utterances. Our findings unravel the detailed cortical layout and computational properties of the neural populations at the basis of human speech recognition and speaker identification.

