---
publish: true
tags: 
project: 
type:
  - timeline
---
# [[Review]], [[MLEM]]
- Computing encoding performance for all layers of BERT/GPT2/Mamba on the word level dataset
# [[Review]], [[Decoding]]
- Computed top 10 retrieval accuracy for the test split of size 1.7k provided by Ziyi for subjects 1, 2, 3 and 4
	- UTS01 1.15%, UTS02 1.66%, UTS03 2.01%, UTS04 1.43%
- Added BrainLLM to Figure 1 and 2
- Added 0 and axis break to Figure 1